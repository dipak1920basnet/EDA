# -*- coding: utf-8 -*-
"""EDA_neural_network.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Whl1I1Vemuygk_FK53nu68vSXIHP9Z_d
"""

import pandas as pd

# Load the dataset to examine its structure and contents
file_path = '/content/wdbc.data'
# Load the dataset without column names to inspect its structure
data = pd.read_csv(file_path, header=None)

# Display basic information about the dataset
data.info()

data.head()

# Assign column names based on common names for the Wisconsin Diagnostic Breast Cancer (WDBC) dataset
# If not, generic names will be used and later adjusted accordingly if labels are available
column_names = [
    "ID", "Diagnosis", "Radius_Mean", "Texture_Mean", "Perimeter_Mean", "Area_Mean", "Smoothness_Mean",
    "Compactness_Mean", "Concavity_Mean", "Concave_Points_Mean", "Symmetry_Mean", "Fractal_Dimension_Mean",
    "Radius_SE", "Texture_SE", "Perimeter_SE", "Area_SE", "Smoothness_SE", "Compactness_SE", "Concavity_SE",
    "Concave_Points_SE", "Symmetry_SE", "Fractal_Dimension_SE", "Radius_Worst", "Texture_Worst",
    "Perimeter_Worst", "Area_Worst", "Smoothness_Worst", "Compactness_Worst", "Concavity_Worst",
    "Concave_Points_Worst", "Symmetry_Worst", "Fractal_Dimension_Worst"
]

# Update the dataset with new column names
data.columns = column_names

# Check the updated column names and a few rows for verification
data.head()

import seaborn as sns
import matplotlib.pyplot as plt

diagnosis_counts = data["Diagnosis"].value_counts()

summary_stats = data.drop(columns="ID").describe()
plt.figure(figsize=(6, 4))
sns.countplot(data=data, x="Diagnosis", palette="Set2")
plt.title("Diagnosis Distribution")
plt.xlabel("Diagnosis")
plt.ylabel("Count")
plt.show()

diagnosis_counts

summary_stats

import seaborn as sns
import matplotlib.pyplot as plt
data['Diagnosis_Numeric'] = data['Diagnosis'].map({'M': 1, 'B': 0})

plt.figure(figsize=(16, 12))
sns.heatmap(data.drop(columns=["ID", "Diagnosis"]).corr(), annot=False, cmap="coolwarm", center=0)
plt.title("Feature Correlation Heatmap")
plt.show()

sns.histplot(data=data, x="Radius_Mean", hue="Diagnosis", multiple="stack", palette="Set1")
plt.title("Distribution of Radius Mean by Diagnosis")
plt.show()

import pandas as pd # Import the pandas library
from sklearn.preprocessing import StandardScaler

# Assuming your data is in a CSV file named 'your_data.csv'
data = pd.read_csv('/content/wdbc.data', header=None) # Load the data into a pandas DataFrame, specifying no header
# Assign column names based on the data description
data.columns = ["ID", "Diagnosis", "Radius_Mean", "Texture_Mean", "Perimeter_Mean", "Area_Mean",
                "Smoothness_Mean", "Compactness_Mean", "Concavity_Mean", "Concave_Points_Mean",
                "Symmetry_Mean", "Fractal_Dimension_Mean", "Radius_SE", "Texture_SE",
                "Perimeter_SE", "Area_SE", "Smoothness_SE", "Compactness_SE", "Concavity_SE",
                "Concave_Points_SE", "Symmetry_SE", "Fractal_Dimension_SE", "Radius_Worst",
                "Texture_Worst", "Perimeter_Worst", "Area_Worst", "Smoothness_Worst",
                "Compactness_Worst", "Concavity_Worst", "Concave_Points_Worst",
                "Symmetry_Worst", "Fractal_Dimension_Worst"]


features = data.drop(columns=["ID", "Diagnosis"])
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)
scaled_data = pd.DataFrame(scaled_features, columns=features.columns) # Use features.columns for correct column names
scaled_data["Diagnosis"] = data["Diagnosis"]
scaled_data.to_csv("scaled_data.csv", index=False)

from sklearn.utils import resample

# Separate classes
benign = data[data["Diagnosis"] == "B"]
malignant = data[data["Diagnosis"] == "M"]

# Downsample benign to match malignant
benign_downsampled = resample(benign, replace=False, n_samples=len(malignant), random_state=42)

# Combine classes
data_balanced = pd.concat([benign_downsampled, malignant])
print(data_balanced["Diagnosis"].value_counts())

